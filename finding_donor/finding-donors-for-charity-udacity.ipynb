{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-17T17:20:53.593810Z","iopub.execute_input":"2022-01-17T17:20:53.594149Z","iopub.status.idle":"2022-01-17T17:20:53.606563Z","shell.execute_reply.started":"2022-01-17T17:20:53.594116Z","shell.execute_reply":"2022-01-17T17:20:53.604978Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 Import all Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import FunctionTransformer, MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:53.608761Z","iopub.execute_input":"2022-01-17T17:20:53.609349Z","iopub.status.idle":"2022-01-17T17:20:53.616845Z","shell.execute_reply.started":"2022-01-17T17:20:53.609307Z","shell.execute_reply":"2022-01-17T17:20:53.615886Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 EDA ","metadata":{}},{"cell_type":"markdown","source":"## Description of the problem\nCharityML is a fictitious charity organization located in the heart of Silicon Valley that was established to provide financial support for people eager to learn machine learning. After nearly 32,000 letters were sent to people in the community, CharityML determined that every donation they received came from someone that was making more than $50,000 annually. To expand their potential donor base, CharityML has decided to send letters to residents of California, but to only those most likely to donate to the charity. With nearly 15 million working Californians, CharityML has brought you on board to help build an algorithm to best identify potential donors and reduce overhead cost of sending mail. Your goal will be evaluate and optimize several different supervised learners to determine which algorithm will provide the highest donation yield while also reducing the total number of letters being sent.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/udacity-mlcharity-competition/census.csv\")\ndf.head(20)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:53.618290Z","iopub.execute_input":"2022-01-17T17:20:53.618784Z","iopub.status.idle":"2022-01-17T17:20:53.784319Z","shell.execute_reply.started":"2022-01-17T17:20:53.618749Z","shell.execute_reply":"2022-01-17T17:20:53.783281Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:53.786684Z","iopub.execute_input":"2022-01-17T17:20:53.787289Z","iopub.status.idle":"2022-01-17T17:20:53.822092Z","shell.execute_reply.started":"2022-01-17T17:20:53.787240Z","shell.execute_reply":"2022-01-17T17:20:53.821307Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"df.shape\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:53.823201Z","iopub.execute_input":"2022-01-17T17:20:53.823476Z","iopub.status.idle":"2022-01-17T17:20:53.884241Z","shell.execute_reply.started":"2022-01-17T17:20:53.823446Z","shell.execute_reply":"2022-01-17T17:20:53.883592Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"#checking for nan´s \ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:53.885683Z","iopub.execute_input":"2022-01-17T17:20:53.886236Z","iopub.status.idle":"2022-01-17T17:20:53.941077Z","shell.execute_reply.started":"2022-01-17T17:20:53.886192Z","shell.execute_reply":"2022-01-17T17:20:53.939969Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:53.942545Z","iopub.execute_input":"2022-01-17T17:20:53.942747Z","iopub.status.idle":"2022-01-17T17:20:53.949439Z","shell.execute_reply.started":"2022-01-17T17:20:53.942722Z","shell.execute_reply":"2022-01-17T17:20:53.948403Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"### Describe the data \n* age: continuous.\n* workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n* education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n* education-num: continuous.\n* marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n* occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n* relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n* race: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other.\n* sex: Female, Male.\n* capital-gain: continuous.\n* capital-loss: continuous.\n* hours-per-week: continuous.\n* native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.","metadata":{}},{"cell_type":"code","source":"#display age distribution \nplt.hist(df['age'], color = 'green', edgecolor = 'black')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:53.952541Z","iopub.execute_input":"2022-01-17T17:20:53.952775Z","iopub.status.idle":"2022-01-17T17:20:54.180802Z","shell.execute_reply.started":"2022-01-17T17:20:53.952749Z","shell.execute_reply":"2022-01-17T17:20:54.179907Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#display maritial status distribution \nplt.hist(df['marital-status'], color = 'green', edgecolor = 'black')\nplt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:54.181979Z","iopub.execute_input":"2022-01-17T17:20:54.182211Z","iopub.status.idle":"2022-01-17T17:20:54.432650Z","shell.execute_reply.started":"2022-01-17T17:20:54.182182Z","shell.execute_reply":"2022-01-17T17:20:54.431920Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"plt.hist(df['race'], color = 'green', edgecolor = 'black')\ndf['race'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:54.437137Z","iopub.execute_input":"2022-01-17T17:20:54.437354Z","iopub.status.idle":"2022-01-17T17:20:54.669848Z","shell.execute_reply.started":"2022-01-17T17:20:54.437327Z","shell.execute_reply":"2022-01-17T17:20:54.668232Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"df['sex'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:54.670850Z","iopub.execute_input":"2022-01-17T17:20:54.671058Z","iopub.status.idle":"2022-01-17T17:20:54.685606Z","shell.execute_reply.started":"2022-01-17T17:20:54.671026Z","shell.execute_reply":"2022-01-17T17:20:54.684584Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"df['income'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:54.686993Z","iopub.execute_input":"2022-01-17T17:20:54.687631Z","iopub.status.idle":"2022-01-17T17:20:54.702231Z","shell.execute_reply.started":"2022-01-17T17:20:54.687570Z","shell.execute_reply":"2022-01-17T17:20:54.701262Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"x = df.groupby(['race', 'income']).size().unstack(fill_value = 0)\ndisplay(x)\nx.plot()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:54.703496Z","iopub.execute_input":"2022-01-17T17:20:54.703791Z","iopub.status.idle":"2022-01-17T17:20:54.961665Z","shell.execute_reply.started":"2022-01-17T17:20:54.703753Z","shell.execute_reply":"2022-01-17T17:20:54.960748Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"y = df.groupby(['sex', 'income']).size().unstack(fill_value = 0)\ny = df.groupby(['sex', 'income']).agg({'race': 'count'})\ndisplay(y)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:54.962819Z","iopub.execute_input":"2022-01-17T17:20:54.963404Z","iopub.status.idle":"2022-01-17T17:20:55.000185Z","shell.execute_reply.started":"2022-01-17T17:20:54.963359Z","shell.execute_reply":"2022-01-17T17:20:54.999384Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"df['income_encoded'] = [1 if value == ' >50K' else 0 for value in df['income'].values]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:55.001135Z","iopub.execute_input":"2022-01-17T17:20:55.001890Z","iopub.status.idle":"2022-01-17T17:20:55.049059Z","shell.execute_reply.started":"2022-01-17T17:20:55.001854Z","shell.execute_reply":"2022-01-17T17:20:55.048120Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df[\"occupation\"], df['income']).plot(kind='barh', stacked=True, figsize=(20, 10))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:55.050704Z","iopub.execute_input":"2022-01-17T17:20:55.051060Z","iopub.status.idle":"2022-01-17T17:20:55.453112Z","shell.execute_reply.started":"2022-01-17T17:20:55.051028Z","shell.execute_reply":"2022-01-17T17:20:55.452549Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df[\"race\"], df['income']).plot(kind='barh', stacked=True, figsize=(10, 5))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:55.454139Z","iopub.execute_input":"2022-01-17T17:20:55.454468Z","iopub.status.idle":"2022-01-17T17:20:55.732785Z","shell.execute_reply.started":"2022-01-17T17:20:55.454440Z","shell.execute_reply":"2022-01-17T17:20:55.731946Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df[\"education-num\"], df['income']).plot(kind='barh', stacked=True, figsize=(10, 5))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:55.734149Z","iopub.execute_input":"2022-01-17T17:20:55.734397Z","iopub.status.idle":"2022-01-17T17:20:56.117809Z","shell.execute_reply.started":"2022-01-17T17:20:55.734370Z","shell.execute_reply":"2022-01-17T17:20:56.117131Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"y = df.groupby(['sex', 'income']).agg({'race': 'count'})\ny","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:56.118815Z","iopub.execute_input":"2022-01-17T17:20:56.119063Z","iopub.status.idle":"2022-01-17T17:20:56.146352Z","shell.execute_reply.started":"2022-01-17T17:20:56.119035Z","shell.execute_reply":"2022-01-17T17:20:56.145784Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion\nthe data are very unevenly distributed. Most of the people in the dataset are white and male. </br> \nfurthermore the income is also very unevely distributed. </br>\nfor example the white male people earn more than 50 in 31.24 pct of the cases, but women only 11.35 pct\nfurthermore you can see that as higher the education is as more likely the person earns more than 50k. \n","metadata":{}},{"cell_type":"code","source":"# TODO: Total number of records\nn_records = len(df)\n\n# TODO: Number of records where individual's income is more than $50,000\nn_greater_50k = len(df[df['income'] == '>50K'])\n\n# TODO: Number of records where individual's income is at most $50,000\nn_at_most_50k = len(df[df['income'] == '<=50K'])\n\n# TODO: Percentage of individuals whose income is more than $50,000\ngreater_percent = (100/n_records)*n_greater_50k\n\n# Print the results\nprint(\"Total number of records: {}\".format(n_records))\nprint(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\nprint(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\nprint(\"Percentage of individuals making more than $50,000: {}%\".format(greater_percent))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:56.147551Z","iopub.execute_input":"2022-01-17T17:20:56.147762Z","iopub.status.idle":"2022-01-17T17:20:56.176053Z","shell.execute_reply.started":"2022-01-17T17:20:56.147738Z","shell.execute_reply":"2022-01-17T17:20:56.174963Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"## 2 Normalizing Numerical Features","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Split the data into features and target label\n#target label\n\nincome_raw = df['income']\nprint(income_raw.head())\n\n\n#feature label\nfeatures_raw = df.drop('income', axis = 1)\nprint(features_raw.head())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:20:56.177259Z","iopub.execute_input":"2022-01-17T17:20:56.177559Z","iopub.status.idle":"2022-01-17T17:20:56.195403Z","shell.execute_reply.started":"2022-01-17T17:20:56.177524Z","shell.execute_reply":"2022-01-17T17:20:56.194590Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"### 2.1 The Scale of Your Data Matters\nMachine learning models learn a mapping from input variables to an output variable.\n\nAs such, the scale and distribution of the data drawn from the domain may be different for each variable.\n\nInput variables may have different units (e.g. feet, kilometers, and hours) that, in turn, may mean the variables have different scales.\n\nDifferences in the scales across input variables may increase the difficulty of the problem being modeled. An example of this is that large input values (e.g. a spread of hundreds or thousands of units) can result in a model that learns large weight values. A model with large weight values is often unstable, meaning that it may suffer from poor performance during learning and sensitivity to input values resulting in higher generalization error.\n\nMin-max scaling is a common feature pre-processing technique which results in scaled data values that fall in the range [0,1]. When applied to a Python sequence, such as a Pandas Series, scaling results in a new sequence such that 0 is the minimum value and 1 is the maximum value of the prior unscaled sequence. If the sequence is [1, 2, 3], then the scaled sequence is [0, 0.5, 1].\n\n\nhttps://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/ </br>\nhttps://www.kite.com/python/answers/how-to-scale-pandas-dataframe-columns-with-the-scikit-learn-minmaxscaler-in-python\n","metadata":{}},{"cell_type":"code","source":"# Log-transform the skewed features\n#we now that this two columns are highly skewed. \nskewed = ['capital-gain', 'capital-loss']\nfeatures_log_transformed = pd.DataFrame(data = features_raw)\nfeatures_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:31:41.609570Z","iopub.execute_input":"2022-01-17T17:31:41.610336Z","iopub.status.idle":"2022-01-17T17:31:41.619733Z","shell.execute_reply.started":"2022-01-17T17:31:41.610295Z","shell.execute_reply":"2022-01-17T17:31:41.618953Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# Import sklearn.preprocessing.StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Initialize a scaler, then apply it to the features\nscaler = MinMaxScaler() # default=(0, 1)\nnumerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n\nfeatures_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\nfeatures_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n\n# Show an example of a record with scaling applied\ndisplay(features_log_minmax_transform.head(n = 5))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:31:53.719222Z","iopub.execute_input":"2022-01-17T17:31:53.719677Z","iopub.status.idle":"2022-01-17T17:31:53.749236Z","shell.execute_reply.started":"2022-01-17T17:31:53.719628Z","shell.execute_reply":"2022-01-17T17:31:53.748386Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"## 3 Data preprocessing\nOur machine learning algorithm can not work with categorical features, we need always numerical data. we got two possibilities to arrange that. One is called Label Encoder and the second is called One-Hot-Encoding. The first one gives all our data a number starting from one, two, and so on. But this means we would have some rank in our machine learning algorithm. Because the number one would rank higher than the number one. this can cause a problem. </br>\nThe second option is that we give all our categorical data a figure between 0 and 1. In the easiest case, we got only two options. For example, we got married and unmarried. Married would get 0 and unmarried would get 0. but if we take divorced also in our data we got already for married 0,0,1 and for unmarried 0,1,0 and for divorced 1,0,0. As you can see this get´s fast a bit confusing. \nIn our case we choose One-Hot-encoding. ","metadata":{}},{"cell_type":"code","source":"# TODO: One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\nfeatures_final = pd.get_dummies(features_log_minmax_transform)\n\n\n# TODO: Encode the 'income_raw' data to numerical values\nincome = income_raw.apply(lambda x: 0 if x == '<=50K' else 1)\n\n# Print the number of features after one-hot encoding\nencoded = list(features_final.columns)\nprint(\"{} total features after one-hot encoding.\".format(len(encoded)))\n\n# Uncomment the following line to see the encoded feature names\nprint(encoded)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:43:52.515386Z","iopub.execute_input":"2022-01-17T17:43:52.515783Z","iopub.status.idle":"2022-01-17T17:43:52.612744Z","shell.execute_reply.started":"2022-01-17T17:43:52.515745Z","shell.execute_reply":"2022-01-17T17:43:52.611971Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}